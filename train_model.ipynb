{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import copy\n",
    "import random\n",
    "import csv\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import operator\n",
    "import json\n",
    "from watson_developer_cloud import NaturalLanguageUnderstandingV1\n",
    "from watson_developer_cloud.natural_language_understanding_v1 import Features, EmotionOptions, SentimentOptions, EntitiesOptions\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Ajinkya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 459 entries, 0 to 458\n",
      "Data columns (total 7 columns):\n",
      "Date               459 non-null object\n",
      "Tweet Full Text    459 non-null object\n",
      "Topic              459 non-null object\n",
      "Action             459 non-null object\n",
      "user id            356 non-null float64\n",
      "follower count     356 non-null float64\n",
      "place              0 non-null float64\n",
      "dtypes: float64(3), object(4)\n",
      "memory usage: 25.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('tweets_train.csv',delimiter=',')\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Community Action    103\n",
      "Traffic              95\n",
      "Appreciation         78\n",
      "Suggestion           51\n",
      "Others               24\n",
      "Follow up            23\n",
      "Query                22\n",
      "Dissatisfaction      21\n",
      "Fraud                17\n",
      "General Info         13\n",
      "Theft                 6\n",
      "Fake News             5\n",
      "Missing Person        1\n",
      "Name: Topic, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "topics = df['Topic'].unique()\n",
    "print(df['Topic'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w) for w in text]\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# text = \"i am Good Good good person\".split()\n",
    "# text = lemmatize_text(text)\n",
    "# vectorizer = CountVectorizer()\n",
    "# print(vectorizer.fit_transform(text).toarray().sum(axis=0))\n",
    "# print(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating TfiDF Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df['Tweet Full Text'].str.cat(sep=' ').lower().replace('thanks','thank').split()\n",
    "text = lemmatize_text(text)\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit_transform(text)\n",
    "# print(vectorizer.vocabulary_.keys())\n",
    "table = pd.DataFrame(index=topics,columns=vectorizer.vocabulary_.keys())\n",
    "table = table.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in list(vectorizer.vocabulary_.keys()):\n",
    "#     if(i=='thanks'):\n",
    "#         print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table Entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zomatocare</th>\n",
       "      <th>hydcitypolice</th>\n",
       "      <th>cyberabadpolice</th>\n",
       "      <th>vijaygopal_</th>\n",
       "      <th>nzomato</th>\n",
       "      <th>accepted</th>\n",
       "      <th>my</th>\n",
       "      <th>order</th>\n",
       "      <th>and</th>\n",
       "      <th>never</th>\n",
       "      <th>...</th>\n",
       "      <th>jio</th>\n",
       "      <th>hqs</th>\n",
       "      <th>knew</th>\n",
       "      <th>ignored</th>\n",
       "      <th>appropriate</th>\n",
       "      <th>cscpcmxoie</th>\n",
       "      <th>raokavitha</th>\n",
       "      <th>needed</th>\n",
       "      <th>deploy</th>\n",
       "      <th>ibtdrbyxeg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Others</th>\n",
       "      <td>2.564949</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012076</td>\n",
       "      <td>0.733169</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>0.017585</td>\n",
       "      <td>0.293267</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.293267</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Follow up</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004025</td>\n",
       "      <td>0.366584</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017585</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Traffic</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020127</td>\n",
       "      <td>0.366584</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004396</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Appreciation</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017585</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fraud</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013188</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              zomatocare  hydcitypolice  cyberabadpolice  vijaygopal_  \\\n",
       "Others          2.564949            0.0         0.012076     0.733169   \n",
       "Follow up       0.000000            0.0         0.004025     0.366584   \n",
       "Traffic         0.000000            0.0         0.020127     0.366584   \n",
       "Appreciation    0.000000            0.0         0.038241     0.000000   \n",
       "Fraud           0.000000            0.0         0.002013     0.000000   \n",
       "\n",
       "               nzomato  accepted        my     order  and     never  \\\n",
       "Others        2.564949  2.564949  0.017585  0.293267  0.0  0.293267   \n",
       "Follow up     0.000000  0.000000  0.017585  0.000000  0.0  0.000000   \n",
       "Traffic       0.000000  0.000000  0.004396  0.000000  0.0  0.000000   \n",
       "Appreciation  0.000000  0.000000  0.017585  0.000000  0.0  0.000000   \n",
       "Fraud         0.000000  0.000000  0.013188  0.000000  0.0  0.000000   \n",
       "\n",
       "                 ...           jio       hqs      knew   ignored  appropriate  \\\n",
       "Others           ...      0.000000  0.000000  0.000000  0.000000     0.000000   \n",
       "Follow up        ...      0.000000  0.000000  0.000000  0.000000     0.000000   \n",
       "Traffic          ...      0.000000  0.000000  0.000000  0.000000     0.000000   \n",
       "Appreciation     ...      0.000000  0.000000  0.000000  0.000000     0.000000   \n",
       "Fraud            ...      2.564949  2.564949  2.564949  2.564949     2.564949   \n",
       "\n",
       "              cscpcmxoie  raokavitha  needed  deploy  ibtdrbyxeg  \n",
       "Others          0.000000         0.0     0.0     0.0         0.0  \n",
       "Follow up       0.000000         0.0     0.0     0.0         0.0  \n",
       "Traffic         0.000000         0.0     0.0     0.0         0.0  \n",
       "Appreciation    0.000000         0.0     0.0     0.0         0.0  \n",
       "Fraud           2.564949         0.0     0.0     0.0         0.0  \n",
       "\n",
       "[5 rows x 3108 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for x in topics:\n",
    "    data = df[df['Topic']==x]\n",
    "    text = data['Tweet Full Text'].str.cat(sep=' ').lower().replace('thanks','thank').split()\n",
    "    text = lemmatize_text(text)\n",
    "#     print(text)\n",
    "    vectorizer = CountVectorizer()\n",
    "    count = vectorizer.fit_transform(text).toarray().sum(axis=0)\n",
    "#     print(x)\n",
    "#     print(count)\n",
    "    name = list(vectorizer.vocabulary_.keys())\n",
    "#     print(x)\n",
    "    for i in range(len(name)):\n",
    "#         if(name[i]=='thank'):\n",
    "#             print(name[i],count[i],vectorizer.vocabulary_['thank'],count[vectorizer.vocabulary_['thank']])\n",
    "        table.loc[x][name[i]] += count[vectorizer.vocabulary_[name[i]]]\n",
    "table = table/table.sum()\n",
    "for c in table:\n",
    "    table[c] = table[c] * math.log( len(table)/len(table[table[c]!=0]))\n",
    "table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.to_csv('table.csv', sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Completed\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    global table\n",
    "    text = text.lower().replace('thanks','thank').replace(\"'\",'').replace('\"','').replace('!','').replace('.',' ').split()\n",
    "    text = lemmatize_text(text)\n",
    "    tp = {}\n",
    "    for i in text:\n",
    "        try:\n",
    "                try:\n",
    "                    tp[table[i].idxmax()] += max(table[i])\n",
    "#                     print(i,table[i].idxmax(),max(table[i]))\n",
    "                except:\n",
    "                    tp[table[i].idxmax()] = max(table[i])\n",
    "#                     print(i,table[i].idxmax(),max(table[i]))\n",
    "        except:\n",
    "            a='f'\n",
    "#     print(tp,text)\n",
    "    if(bool(tp) == False):\n",
    "        return 'Others'\n",
    "    return  max(tp.items(), key=operator.itemgetter(1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Appreciation'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"b'@TelanganaDGP @cpnizamabad @CPHydCity @hydcitypolice @sp_kamareddy @spkamareddy Thank you so much sir For Your Response \\xf0\\x9f\\x99\\x8f @TelanganaDGP'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9281045751633987"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['predictions'] = df['Tweet Full Text'].apply(predict)\n",
    "df[\"classification_correct\"] = df[\"predictions\"] == df[\"Topic\"]\n",
    "df['classification_correct'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment , Emotion, Entitiy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "natural_language_understanding = NaturalLanguageUnderstandingV1(\n",
    "    version='2018-11-16',\n",
    "    iam_apikey='TQHgzc_QZ5w9hjhnYdFkWN0lrJk4AaXB4PkJXltCL-fA',\n",
    "    url='https://gateway-lon.watsonplatform.net/natural-language-understanding/api'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = natural_language_understanding.analyze(\n",
    "#     text=\"b'@HYDTP @hydcitypolice @AddlCPTrHyd Good initiative'\",\n",
    "#     features=Features(sentiment=SentimentOptions(),emotion=EmotionOptions(),entities=EntitiesOptions())).get_result()\n",
    "# print(json.loads(json.dumps(response['emotion']['document']['emotion'])))\n",
    "# print(json.loads(json.dumps(response['sentiment']['document']['score'])))\n",
    "# json.loads(json.dumps(response['entities'][0]['type']))=='Location'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Tweet Full Text</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Action</th>\n",
       "      <th>user id</th>\n",
       "      <th>follower count</th>\n",
       "      <th>place</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2/25/19 6:34</td>\n",
       "      <td>b'@zomatocare @hydcitypolice \\n@cyberabadpolic...</td>\n",
       "      <td>Others</td>\n",
       "      <td>NS</td>\n",
       "      <td>1.080000e+18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.339199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2/25/19 5:15</td>\n",
       "      <td>b'@hydcitypolice Sir, any updates regarding my...</td>\n",
       "      <td>Follow up</td>\n",
       "      <td>S</td>\n",
       "      <td>1.040000e+18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.761524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2/24/19 5:59</td>\n",
       "      <td>b'@HYDTP @CPHydCity @hydcitypolice @TelanganaD...</td>\n",
       "      <td>Traffic</td>\n",
       "      <td>NS</td>\n",
       "      <td>1.090000e+18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03-01-2019 14:32</td>\n",
       "      <td>b'@HYDTP @hydcitypolice @AddlCPTrHyd Good init...</td>\n",
       "      <td>Appreciation</td>\n",
       "      <td>NS</td>\n",
       "      <td>1.400108e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.901576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03-01-2019 12:34</td>\n",
       "      <td>b'@USCGHyderabad @TelanganaDGP @USAndHyderabad...</td>\n",
       "      <td>Appreciation</td>\n",
       "      <td>NS</td>\n",
       "      <td>1.050000e+18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.965338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Date                                    Tweet Full Text  \\\n",
       "0      2/25/19 6:34  b'@zomatocare @hydcitypolice \\n@cyberabadpolic...   \n",
       "1      2/25/19 5:15  b'@hydcitypolice Sir, any updates regarding my...   \n",
       "2      2/24/19 5:59  b'@HYDTP @CPHydCity @hydcitypolice @TelanganaD...   \n",
       "3  03-01-2019 14:32  b'@HYDTP @hydcitypolice @AddlCPTrHyd Good init...   \n",
       "4  03-01-2019 12:34  b'@USCGHyderabad @TelanganaDGP @USAndHyderabad...   \n",
       "\n",
       "          Topic Action       user id  follower count  place     score  \n",
       "0        Others     NS  1.080000e+18             0.0    NaN  0.339199  \n",
       "1     Follow up      S  1.040000e+18             0.0    NaN -0.761524  \n",
       "2       Traffic     NS  1.090000e+18             0.0    NaN  0.000000  \n",
       "3  Appreciation     NS  1.400108e+08             0.0    NaN  0.901576  \n",
       "4  Appreciation     NS  1.050000e+18             0.0    NaN  0.965338  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = []\n",
    "mydict = {}\n",
    "for i in df['Tweet Full Text']:\n",
    "    response2 = natural_language_understanding.analyze(\n",
    "        text=i,\n",
    "        features=Features(sentiment=SentimentOptions()),\n",
    "        language='en'\n",
    "    ).get_result()\n",
    "    mydict['score'] = json.loads(json.dumps(response2['sentiment']['document']['score']))  \n",
    "    try:\n",
    "        score.append(mydict['score'])\n",
    "    except:\n",
    "        score.append(0)\n",
    "df['score'] = score\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Tweet Full Text</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Action</th>\n",
       "      <th>user id</th>\n",
       "      <th>follower count</th>\n",
       "      <th>place</th>\n",
       "      <th>score</th>\n",
       "      <th>sadness</th>\n",
       "      <th>joy</th>\n",
       "      <th>fear</th>\n",
       "      <th>disgust</th>\n",
       "      <th>anger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2/25/19 6:34</td>\n",
       "      <td>b'@zomatocare @hydcitypolice \\n@cyberabadpolic...</td>\n",
       "      <td>Others</td>\n",
       "      <td>NS</td>\n",
       "      <td>1.080000e+18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.339199</td>\n",
       "      <td>0.105245</td>\n",
       "      <td>0.225655</td>\n",
       "      <td>0.001491</td>\n",
       "      <td>0.002787</td>\n",
       "      <td>0.023300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2/25/19 5:15</td>\n",
       "      <td>b'@hydcitypolice Sir, any updates regarding my...</td>\n",
       "      <td>Follow up</td>\n",
       "      <td>S</td>\n",
       "      <td>1.040000e+18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.761524</td>\n",
       "      <td>0.162827</td>\n",
       "      <td>0.033009</td>\n",
       "      <td>0.013693</td>\n",
       "      <td>0.125967</td>\n",
       "      <td>0.187487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2/24/19 5:59</td>\n",
       "      <td>b'@HYDTP @CPHydCity @hydcitypolice @TelanganaD...</td>\n",
       "      <td>Traffic</td>\n",
       "      <td>NS</td>\n",
       "      <td>1.090000e+18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.141880</td>\n",
       "      <td>0.146321</td>\n",
       "      <td>0.088611</td>\n",
       "      <td>0.105356</td>\n",
       "      <td>0.080799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03-01-2019 14:32</td>\n",
       "      <td>b'@HYDTP @hydcitypolice @AddlCPTrHyd Good init...</td>\n",
       "      <td>Appreciation</td>\n",
       "      <td>NS</td>\n",
       "      <td>1.400108e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.901576</td>\n",
       "      <td>0.054764</td>\n",
       "      <td>0.780943</td>\n",
       "      <td>0.050431</td>\n",
       "      <td>0.014236</td>\n",
       "      <td>0.026168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03-01-2019 12:34</td>\n",
       "      <td>b'@USCGHyderabad @TelanganaDGP @USAndHyderabad...</td>\n",
       "      <td>Appreciation</td>\n",
       "      <td>NS</td>\n",
       "      <td>1.050000e+18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.965338</td>\n",
       "      <td>0.002762</td>\n",
       "      <td>0.835799</td>\n",
       "      <td>0.001891</td>\n",
       "      <td>0.001063</td>\n",
       "      <td>0.012618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Date                                    Tweet Full Text  \\\n",
       "0      2/25/19 6:34  b'@zomatocare @hydcitypolice \\n@cyberabadpolic...   \n",
       "1      2/25/19 5:15  b'@hydcitypolice Sir, any updates regarding my...   \n",
       "2      2/24/19 5:59  b'@HYDTP @CPHydCity @hydcitypolice @TelanganaD...   \n",
       "3  03-01-2019 14:32  b'@HYDTP @hydcitypolice @AddlCPTrHyd Good init...   \n",
       "4  03-01-2019 12:34  b'@USCGHyderabad @TelanganaDGP @USAndHyderabad...   \n",
       "\n",
       "          Topic Action       user id  follower count  place     score  \\\n",
       "0        Others     NS  1.080000e+18             0.0    NaN  0.339199   \n",
       "1     Follow up      S  1.040000e+18             0.0    NaN -0.761524   \n",
       "2       Traffic     NS  1.090000e+18             0.0    NaN  0.000000   \n",
       "3  Appreciation     NS  1.400108e+08             0.0    NaN  0.901576   \n",
       "4  Appreciation     NS  1.050000e+18             0.0    NaN  0.965338   \n",
       "\n",
       "    sadness       joy      fear   disgust     anger  \n",
       "0  0.105245  0.225655  0.001491  0.002787  0.023300  \n",
       "1  0.162827  0.033009  0.013693  0.125967  0.187487  \n",
       "2  0.141880  0.146321  0.088611  0.105356  0.080799  \n",
       "3  0.054764  0.780943  0.050431  0.014236  0.026168  \n",
       "4  0.002762  0.835799  0.001891  0.001063  0.012618  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sadness,joy,fear,disgust,anger = [],[],[],[],[]\n",
    "mydict = {}\n",
    "for i in df['Tweet Full Text']:\n",
    "    response2 = natural_language_understanding.analyze(\n",
    "        text=i,\n",
    "        features=Features(emotion=EmotionOptions()),\n",
    "        language='en'\n",
    "    ).get_result()\n",
    "    mydict = json.loads(json.dumps(response2['emotion']['document']['emotion']))\n",
    "    sadness.append(mydict['sadness'])\n",
    "    joy.append(mydict['joy'])\n",
    "    fear.append(mydict['fear'])\n",
    "    disgust.append(mydict['disgust'])\n",
    "    anger.append(mydict['anger'])\n",
    "df['sadness'] = sadness\n",
    "df['joy'] = joy\n",
    "df['fear'] = fear\n",
    "df['disgust'] = disgust\n",
    "df['anger'] = anger\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Tweet Full Text</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Action</th>\n",
       "      <th>user id</th>\n",
       "      <th>follower count</th>\n",
       "      <th>place</th>\n",
       "      <th>score</th>\n",
       "      <th>sadness</th>\n",
       "      <th>joy</th>\n",
       "      <th>fear</th>\n",
       "      <th>disgust</th>\n",
       "      <th>anger</th>\n",
       "      <th>predictions</th>\n",
       "      <th>classification_correct</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2/25/19 6:34</td>\n",
       "      <td>b'@zomatocare @hydcitypolice \\n@cyberabadpolic...</td>\n",
       "      <td>Others</td>\n",
       "      <td>NS</td>\n",
       "      <td>1.080000e+18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.339199</td>\n",
       "      <td>0.105245</td>\n",
       "      <td>0.225655</td>\n",
       "      <td>0.001491</td>\n",
       "      <td>0.002787</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>Others</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2/25/19 5:15</td>\n",
       "      <td>b'@hydcitypolice Sir, any updates regarding my...</td>\n",
       "      <td>Follow up</td>\n",
       "      <td>S</td>\n",
       "      <td>1.040000e+18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.761524</td>\n",
       "      <td>0.162827</td>\n",
       "      <td>0.033009</td>\n",
       "      <td>0.013693</td>\n",
       "      <td>0.125967</td>\n",
       "      <td>0.187487</td>\n",
       "      <td>Follow up</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2/24/19 5:59</td>\n",
       "      <td>b'@HYDTP @CPHydCity @hydcitypolice @TelanganaD...</td>\n",
       "      <td>Traffic</td>\n",
       "      <td>NS</td>\n",
       "      <td>1.090000e+18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.141880</td>\n",
       "      <td>0.146321</td>\n",
       "      <td>0.088611</td>\n",
       "      <td>0.105356</td>\n",
       "      <td>0.080799</td>\n",
       "      <td>Traffic</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03-01-2019 14:32</td>\n",
       "      <td>b'@HYDTP @hydcitypolice @AddlCPTrHyd Good init...</td>\n",
       "      <td>Appreciation</td>\n",
       "      <td>NS</td>\n",
       "      <td>1.400108e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.901576</td>\n",
       "      <td>0.054764</td>\n",
       "      <td>0.780943</td>\n",
       "      <td>0.050431</td>\n",
       "      <td>0.014236</td>\n",
       "      <td>0.026168</td>\n",
       "      <td>Appreciation</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03-01-2019 12:34</td>\n",
       "      <td>b'@USCGHyderabad @TelanganaDGP @USAndHyderabad...</td>\n",
       "      <td>Appreciation</td>\n",
       "      <td>NS</td>\n",
       "      <td>1.050000e+18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.965338</td>\n",
       "      <td>0.002762</td>\n",
       "      <td>0.835799</td>\n",
       "      <td>0.001891</td>\n",
       "      <td>0.001063</td>\n",
       "      <td>0.012618</td>\n",
       "      <td>Appreciation</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Date                                    Tweet Full Text  \\\n",
       "0      2/25/19 6:34  b'@zomatocare @hydcitypolice \\n@cyberabadpolic...   \n",
       "1      2/25/19 5:15  b'@hydcitypolice Sir, any updates regarding my...   \n",
       "2      2/24/19 5:59  b'@HYDTP @CPHydCity @hydcitypolice @TelanganaD...   \n",
       "3  03-01-2019 14:32  b'@HYDTP @hydcitypolice @AddlCPTrHyd Good init...   \n",
       "4  03-01-2019 12:34  b'@USCGHyderabad @TelanganaDGP @USAndHyderabad...   \n",
       "\n",
       "          Topic Action       user id  follower count  place     score  \\\n",
       "0        Others     NS  1.080000e+18             0.0    NaN  0.339199   \n",
       "1     Follow up      S  1.040000e+18             0.0    NaN -0.761524   \n",
       "2       Traffic     NS  1.090000e+18             0.0    NaN  0.000000   \n",
       "3  Appreciation     NS  1.400108e+08             0.0    NaN  0.901576   \n",
       "4  Appreciation     NS  1.050000e+18             0.0    NaN  0.965338   \n",
       "\n",
       "    sadness       joy      fear   disgust     anger   predictions  \\\n",
       "0  0.105245  0.225655  0.001491  0.002787  0.023300        Others   \n",
       "1  0.162827  0.033009  0.013693  0.125967  0.187487     Follow up   \n",
       "2  0.141880  0.146321  0.088611  0.105356  0.080799       Traffic   \n",
       "3  0.054764  0.780943  0.050431  0.014236  0.026168  Appreciation   \n",
       "4  0.002762  0.835799  0.001891  0.001063  0.012618  Appreciation   \n",
       "\n",
       "   classification_correct location  \n",
       "0                    True    False  \n",
       "1                    True    False  \n",
       "2                    True    False  \n",
       "3                    True    False  \n",
       "4                    True    False  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location = []\n",
    "mydict = {}\n",
    "for i in df['Tweet Full Text']:\n",
    "    response2 = natural_language_understanding.analyze(\n",
    "        text=i,\n",
    "        features=Features(entities=EntitiesOptions()),\n",
    "        language='en'\n",
    "    ).get_result()\n",
    "    try:\n",
    "        mydict['location'] = (json.loads(json.dumps(response2['entities'][0]['type'])) == 'Location')\n",
    "    except:\n",
    "        mydict['location'] = 'False'\n",
    "    location.append(mydict['location'])\n",
    "df['location'] = location\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Train data and Table data (tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('train_df.csv', sep=',', encoding='utf-8')\n",
    "table.to_csv('table.csv', sep=',', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
