{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import copy\n",
    "import random\n",
    "import csv\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import operator\n",
    "import json\n",
    "from watson_developer_cloud import NaturalLanguageUnderstandingV1\n",
    "from watson_developer_cloud.natural_language_understanding_v1 import Features, EmotionOptions, SentimentOptions, EntitiesOptions\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Ajinkya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 459 entries, 0 to 458\n",
      "Data columns (total 7 columns):\n",
      "Date               459 non-null object\n",
      "Tweet Full Text    459 non-null object\n",
      "Topic              459 non-null object\n",
      "Action             459 non-null object\n",
      "user id            356 non-null float64\n",
      "follower count     356 non-null float64\n",
      "place              0 non-null float64\n",
      "dtypes: float64(3), object(4)\n",
      "memory usage: 25.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('tweets1.csv',delimiter=',')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Community Action    103\n",
       "Traffic              95\n",
       "Appreciation         78\n",
       "Suggestion           51\n",
       "Others               24\n",
       "Follow up            23\n",
       "Query                22\n",
       "Dissatisfaction      21\n",
       "Fraud                17\n",
       "General Info         13\n",
       "Theft                 6\n",
       "Fake News             5\n",
       "Missing Person        1\n",
       "Name: Topic, dtype: int64"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics = df['Topic'].unique()\n",
    "df['Topic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w) for w in text]\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'am': 0, 'good': 1, 'person': 2}"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"i am Good Good good person\".split()\n",
    "text = lemmatize_text(text)\n",
    "vectorizer = CountVectorizer()\n",
    "print(vectorizer.fit_transform(text).toarray().sum(axis=0))\n",
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating TfiDF Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df['Tweet Full Text'].str.cat(sep=' ').lower().replace('thanks','thank').split()\n",
    "text = lemmatize_text(text)\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit_transform(text)\n",
    "# print(vectorizer.vocabulary_.keys())\n",
    "table = pd.DataFrame(index=topics,columns=vectorizer.vocabulary_.keys())\n",
    "table = table.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in list(vectorizer.vocabulary_.keys()):\n",
    "    if(i=='thanks'):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table Entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zomatocare</th>\n",
       "      <th>hydcitypolice</th>\n",
       "      <th>cyberabadpolice</th>\n",
       "      <th>vijaygopal_</th>\n",
       "      <th>nzomato</th>\n",
       "      <th>accepted</th>\n",
       "      <th>my</th>\n",
       "      <th>order</th>\n",
       "      <th>and</th>\n",
       "      <th>never</th>\n",
       "      <th>...</th>\n",
       "      <th>jio</th>\n",
       "      <th>hqs</th>\n",
       "      <th>knew</th>\n",
       "      <th>ignored</th>\n",
       "      <th>appropriate</th>\n",
       "      <th>cscpcmxoie</th>\n",
       "      <th>raokavitha</th>\n",
       "      <th>needed</th>\n",
       "      <th>deploy</th>\n",
       "      <th>ibtdrbyxeg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Others</th>\n",
       "      <td>2.564949</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012076</td>\n",
       "      <td>0.733169</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>0.017585</td>\n",
       "      <td>0.293267</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.293267</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Follow up</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004025</td>\n",
       "      <td>0.366584</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017585</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Traffic</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020127</td>\n",
       "      <td>0.366584</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004396</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Appreciation</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017585</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fraud</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013188</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Query</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008051</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013188</td>\n",
       "      <td>0.293267</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Community Action</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052330</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035169</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.586535</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>2.564949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Suggestion</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012076</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008792</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.586535</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dissatisfaction</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004025</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.879802</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>General Info</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012076</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004396</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fake News</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Theft</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030773</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Missing Person</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004396</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13 rows × 3108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  zomatocare  hydcitypolice  cyberabadpolice  vijaygopal_  \\\n",
       "Others              2.564949            0.0         0.012076     0.733169   \n",
       "Follow up           0.000000            0.0         0.004025     0.366584   \n",
       "Traffic             0.000000            0.0         0.020127     0.366584   \n",
       "Appreciation        0.000000            0.0         0.038241     0.000000   \n",
       "Fraud               0.000000            0.0         0.002013     0.000000   \n",
       "Query               0.000000            0.0         0.008051     0.000000   \n",
       "Community Action    0.000000            0.0         0.052330     0.000000   \n",
       "Suggestion          0.000000            0.0         0.012076     0.000000   \n",
       "Dissatisfaction     0.000000            0.0         0.004025     0.000000   \n",
       "General Info        0.000000            0.0         0.012076     0.000000   \n",
       "Fake News           0.000000            0.0         0.002013     0.000000   \n",
       "Theft               0.000000            0.0         0.000000     0.000000   \n",
       "Missing Person      0.000000            0.0         0.000000     0.000000   \n",
       "\n",
       "                   nzomato  accepted        my     order  and     never  \\\n",
       "Others            2.564949  2.564949  0.017585  0.293267  0.0  0.293267   \n",
       "Follow up         0.000000  0.000000  0.017585  0.000000  0.0  0.000000   \n",
       "Traffic           0.000000  0.000000  0.004396  0.000000  0.0  0.000000   \n",
       "Appreciation      0.000000  0.000000  0.017585  0.000000  0.0  0.000000   \n",
       "Fraud             0.000000  0.000000  0.013188  0.000000  0.0  0.000000   \n",
       "Query             0.000000  0.000000  0.013188  0.293267  0.0  0.000000   \n",
       "Community Action  0.000000  0.000000  0.035169  0.000000  0.0  0.586535   \n",
       "Suggestion        0.000000  0.000000  0.008792  0.000000  0.0  0.586535   \n",
       "Dissatisfaction   0.000000  0.000000  0.000000  0.879802  0.0  0.000000   \n",
       "General Info      0.000000  0.000000  0.004396  0.000000  0.0  0.000000   \n",
       "Fake News         0.000000  0.000000  0.000000  0.000000  0.0  0.000000   \n",
       "Theft             0.000000  0.000000  0.030773  0.000000  0.0  0.000000   \n",
       "Missing Person    0.000000  0.000000  0.004396  0.000000  0.0  0.000000   \n",
       "\n",
       "                     ...           jio       hqs      knew   ignored  \\\n",
       "Others               ...      0.000000  0.000000  0.000000  0.000000   \n",
       "Follow up            ...      0.000000  0.000000  0.000000  0.000000   \n",
       "Traffic              ...      0.000000  0.000000  0.000000  0.000000   \n",
       "Appreciation         ...      0.000000  0.000000  0.000000  0.000000   \n",
       "Fraud                ...      2.564949  2.564949  2.564949  2.564949   \n",
       "Query                ...      0.000000  0.000000  0.000000  0.000000   \n",
       "Community Action     ...      0.000000  0.000000  0.000000  0.000000   \n",
       "Suggestion           ...      0.000000  0.000000  0.000000  0.000000   \n",
       "Dissatisfaction      ...      0.000000  0.000000  0.000000  0.000000   \n",
       "General Info         ...      0.000000  0.000000  0.000000  0.000000   \n",
       "Fake News            ...      0.000000  0.000000  0.000000  0.000000   \n",
       "Theft                ...      0.000000  0.000000  0.000000  0.000000   \n",
       "Missing Person       ...      0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "                  appropriate  cscpcmxoie  raokavitha    needed    deploy  \\\n",
       "Others               0.000000    0.000000    0.000000  0.000000  0.000000   \n",
       "Follow up            0.000000    0.000000    0.000000  0.000000  0.000000   \n",
       "Traffic              0.000000    0.000000    0.000000  0.000000  0.000000   \n",
       "Appreciation         0.000000    0.000000    0.000000  0.000000  0.000000   \n",
       "Fraud                2.564949    2.564949    0.000000  0.000000  0.000000   \n",
       "Query                0.000000    0.000000    0.000000  0.000000  0.000000   \n",
       "Community Action     0.000000    0.000000    2.564949  2.564949  2.564949   \n",
       "Suggestion           0.000000    0.000000    0.000000  0.000000  0.000000   \n",
       "Dissatisfaction      0.000000    0.000000    0.000000  0.000000  0.000000   \n",
       "General Info         0.000000    0.000000    0.000000  0.000000  0.000000   \n",
       "Fake News            0.000000    0.000000    0.000000  0.000000  0.000000   \n",
       "Theft                0.000000    0.000000    0.000000  0.000000  0.000000   \n",
       "Missing Person       0.000000    0.000000    0.000000  0.000000  0.000000   \n",
       "\n",
       "                  ibtdrbyxeg  \n",
       "Others              0.000000  \n",
       "Follow up           0.000000  \n",
       "Traffic             0.000000  \n",
       "Appreciation        0.000000  \n",
       "Fraud               0.000000  \n",
       "Query               0.000000  \n",
       "Community Action    2.564949  \n",
       "Suggestion          0.000000  \n",
       "Dissatisfaction     0.000000  \n",
       "General Info        0.000000  \n",
       "Fake News           0.000000  \n",
       "Theft               0.000000  \n",
       "Missing Person      0.000000  \n",
       "\n",
       "[13 rows x 3108 columns]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for x in topics:\n",
    "    data = df[df['Topic']==x]\n",
    "    text = data['Tweet Full Text'].str.cat(sep=' ').lower().replace('thanks','thank').split()\n",
    "    text = lemmatize_text(text)\n",
    "#     print(text)\n",
    "    vectorizer = CountVectorizer()\n",
    "    count = vectorizer.fit_transform(text).toarray().sum(axis=0)\n",
    "#     print(x)\n",
    "#     print(count)\n",
    "    name = list(vectorizer.vocabulary_.keys())\n",
    "#     print(x)\n",
    "    for i in range(len(name)):\n",
    "#         if(name[i]=='thank'):\n",
    "#             print(name[i],count[i],vectorizer.vocabulary_['thank'],count[vectorizer.vocabulary_['thank']])\n",
    "        table.loc[x][name[i]] += count[vectorizer.vocabulary_[name[i]]]\n",
    "table = table/table.sum()\n",
    "for c in table:\n",
    "    table[c] = table[c] * math.log( len(table)/len(table[table[c]!=0]))\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    global table\n",
    "    text = text.lower().replace('thanks','thank').replace(\"'\",'').replace('\"','').replace('!','').replace('.',' ').split()\n",
    "    text = lemmatize_text(text)\n",
    "    tp = {}\n",
    "    for i in text:\n",
    "        try:\n",
    "                try:\n",
    "                    tp[table[i].idxmax()] += max(table[i])\n",
    "#                     print(i,table[i].idxmax(),max(table[i]))\n",
    "                except:\n",
    "                    tp[table[i].idxmax()] = max(table[i])\n",
    "#                     print(i,table[i].idxmax(),max(table[i]))\n",
    "        except:\n",
    "            a='f'\n",
    "#     print(tp,text)\n",
    "    if(bool(tp) == False):\n",
    "        return 'Others'\n",
    "    return  max(tp.items(), key=operator.itemgetter(1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Appreciation'"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"b'@TelanganaDGP @cpnizamabad @CPHydCity @hydcitypolice @sp_kamareddy @spkamareddy Thank you so much sir For Your Response \\xf0\\x9f\\x99\\x8f @TelanganaDGP'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9281045751633987"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['predictions'] = df['Tweet Full Text'].apply(predict)\n",
    "df[\"classification_correct\"] = df[\"predictions\"] == df[\"Topic\"]\n",
    "df['classification_correct'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment , Emotion, Entitiy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "natural_language_understanding = NaturalLanguageUnderstandingV1(\n",
    "    version='2018-11-16',\n",
    "    iam_apikey='TQHgzc_QZ5w9hjhnYdFkWN0lrJk4AaXB4PkJXltCL-fA',\n",
    "    url='https://gateway-lon.watsonplatform.net/natural-language-understanding/api'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sadness': 0.054764, 'joy': 0.780943, 'fear': 0.050431, 'disgust': 0.014236, 'anger': 0.026168}\n",
      "0.901576\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = natural_language_understanding.analyze(\n",
    "    text=\"b'@HYDTP @hydcitypolice @AddlCPTrHyd Good initiative'\",\n",
    "    features=Features(sentiment=SentimentOptions(),emotion=EmotionOptions(),entities=EntitiesOptions())).get_result()\n",
    "print(json.loads(json.dumps(response['emotion']['document']['emotion'])))\n",
    "print(json.loads(json.dumps(response['sentiment']['document']['score'])))\n",
    "json.loads(json.dumps(response['entities'][0]['type']))=='Location'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Tweet Full Text</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Action</th>\n",
       "      <th>user id</th>\n",
       "      <th>follower count</th>\n",
       "      <th>place</th>\n",
       "      <th>predictions</th>\n",
       "      <th>classification_correct</th>\n",
       "      <th>sadness</th>\n",
       "      <th>joy</th>\n",
       "      <th>fear</th>\n",
       "      <th>disgust</th>\n",
       "      <th>anger</th>\n",
       "      <th>score</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2/25/19 6:34</td>\n",
       "      <td>b'@zomatocare @hydcitypolice \\n@cyberabadpolic...</td>\n",
       "      <td>Others</td>\n",
       "      <td>NS</td>\n",
       "      <td>1.080000e+18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Others</td>\n",
       "      <td>True</td>\n",
       "      <td>0.105245</td>\n",
       "      <td>0.225655</td>\n",
       "      <td>0.001491</td>\n",
       "      <td>0.002787</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>0.339199</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2/25/19 5:15</td>\n",
       "      <td>b'@hydcitypolice Sir, any updates regarding my...</td>\n",
       "      <td>Follow up</td>\n",
       "      <td>S</td>\n",
       "      <td>1.040000e+18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Follow up</td>\n",
       "      <td>True</td>\n",
       "      <td>0.162827</td>\n",
       "      <td>0.033009</td>\n",
       "      <td>0.013693</td>\n",
       "      <td>0.125967</td>\n",
       "      <td>0.187487</td>\n",
       "      <td>-0.761524</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2/24/19 5:59</td>\n",
       "      <td>b'@HYDTP @CPHydCity @hydcitypolice @TelanganaD...</td>\n",
       "      <td>Traffic</td>\n",
       "      <td>NS</td>\n",
       "      <td>1.090000e+18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Traffic</td>\n",
       "      <td>True</td>\n",
       "      <td>0.141880</td>\n",
       "      <td>0.146321</td>\n",
       "      <td>0.088611</td>\n",
       "      <td>0.105356</td>\n",
       "      <td>0.080799</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03-01-2019 14:32</td>\n",
       "      <td>b'@HYDTP @hydcitypolice @AddlCPTrHyd Good init...</td>\n",
       "      <td>Appreciation</td>\n",
       "      <td>NS</td>\n",
       "      <td>1.400108e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Appreciation</td>\n",
       "      <td>True</td>\n",
       "      <td>0.054764</td>\n",
       "      <td>0.780943</td>\n",
       "      <td>0.050431</td>\n",
       "      <td>0.014236</td>\n",
       "      <td>0.026168</td>\n",
       "      <td>0.901576</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03-01-2019 12:34</td>\n",
       "      <td>b'@USCGHyderabad @TelanganaDGP @USAndHyderabad...</td>\n",
       "      <td>Appreciation</td>\n",
       "      <td>NS</td>\n",
       "      <td>1.050000e+18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Appreciation</td>\n",
       "      <td>True</td>\n",
       "      <td>0.002762</td>\n",
       "      <td>0.835799</td>\n",
       "      <td>0.001891</td>\n",
       "      <td>0.001063</td>\n",
       "      <td>0.012618</td>\n",
       "      <td>0.965338</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Date                                    Tweet Full Text  \\\n",
       "0      2/25/19 6:34  b'@zomatocare @hydcitypolice \\n@cyberabadpolic...   \n",
       "1      2/25/19 5:15  b'@hydcitypolice Sir, any updates regarding my...   \n",
       "2      2/24/19 5:59  b'@HYDTP @CPHydCity @hydcitypolice @TelanganaD...   \n",
       "3  03-01-2019 14:32  b'@HYDTP @hydcitypolice @AddlCPTrHyd Good init...   \n",
       "4  03-01-2019 12:34  b'@USCGHyderabad @TelanganaDGP @USAndHyderabad...   \n",
       "\n",
       "          Topic Action       user id  follower count  place   predictions  \\\n",
       "0        Others     NS  1.080000e+18             0.0    NaN        Others   \n",
       "1     Follow up      S  1.040000e+18             0.0    NaN     Follow up   \n",
       "2       Traffic     NS  1.090000e+18             0.0    NaN       Traffic   \n",
       "3  Appreciation     NS  1.400108e+08             0.0    NaN  Appreciation   \n",
       "4  Appreciation     NS  1.050000e+18             0.0    NaN  Appreciation   \n",
       "\n",
       "   classification_correct   sadness       joy      fear   disgust     anger  \\\n",
       "0                    True  0.105245  0.225655  0.001491  0.002787  0.023300   \n",
       "1                    True  0.162827  0.033009  0.013693  0.125967  0.187487   \n",
       "2                    True  0.141880  0.146321  0.088611  0.105356  0.080799   \n",
       "3                    True  0.054764  0.780943  0.050431  0.014236  0.026168   \n",
       "4                    True  0.002762  0.835799  0.001891  0.001063  0.012618   \n",
       "\n",
       "      score  location  \n",
       "0  0.339199      True  \n",
       "1 -0.761524      True  \n",
       "2  0.000000      True  \n",
       "3  0.901576      True  \n",
       "4  0.965338      True  "
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = []\n",
    "for i in df['Tweet Full Text']:\n",
    "    response2 = natural_language_understanding.analyze(\n",
    "        text=i,\n",
    "        features=Features(sentiment=SentimentOptions()),\n",
    "        language='en'\n",
    "    ).get_result()\n",
    "    mydict['score'] = json.loads(json.dumps(response2['sentiment']['document']['score']))  \n",
    "    try:\n",
    "        score.append(mydict['score'])\n",
    "    except:\n",
    "        score.append(0)\n",
    "df['score'] = score\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Tweet Full Text</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Action</th>\n",
       "      <th>user id</th>\n",
       "      <th>follower count</th>\n",
       "      <th>place</th>\n",
       "      <th>predictions</th>\n",
       "      <th>classification_correct</th>\n",
       "      <th>sadness</th>\n",
       "      <th>joy</th>\n",
       "      <th>fear</th>\n",
       "      <th>disgust</th>\n",
       "      <th>anger</th>\n",
       "      <th>score</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2/25/19 6:34</td>\n",
       "      <td>b'@zomatocare @hydcitypolice \\n@cyberabadpolic...</td>\n",
       "      <td>Others</td>\n",
       "      <td>NS</td>\n",
       "      <td>1.080000e+18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Others</td>\n",
       "      <td>True</td>\n",
       "      <td>0.105245</td>\n",
       "      <td>0.225655</td>\n",
       "      <td>0.001491</td>\n",
       "      <td>0.002787</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>0.339199</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2/25/19 5:15</td>\n",
       "      <td>b'@hydcitypolice Sir, any updates regarding my...</td>\n",
       "      <td>Follow up</td>\n",
       "      <td>S</td>\n",
       "      <td>1.040000e+18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Follow up</td>\n",
       "      <td>True</td>\n",
       "      <td>0.162827</td>\n",
       "      <td>0.033009</td>\n",
       "      <td>0.013693</td>\n",
       "      <td>0.125967</td>\n",
       "      <td>0.187487</td>\n",
       "      <td>-0.761524</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2/24/19 5:59</td>\n",
       "      <td>b'@HYDTP @CPHydCity @hydcitypolice @TelanganaD...</td>\n",
       "      <td>Traffic</td>\n",
       "      <td>NS</td>\n",
       "      <td>1.090000e+18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Traffic</td>\n",
       "      <td>True</td>\n",
       "      <td>0.141880</td>\n",
       "      <td>0.146321</td>\n",
       "      <td>0.088611</td>\n",
       "      <td>0.105356</td>\n",
       "      <td>0.080799</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03-01-2019 14:32</td>\n",
       "      <td>b'@HYDTP @hydcitypolice @AddlCPTrHyd Good init...</td>\n",
       "      <td>Appreciation</td>\n",
       "      <td>NS</td>\n",
       "      <td>1.400108e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Appreciation</td>\n",
       "      <td>True</td>\n",
       "      <td>0.054764</td>\n",
       "      <td>0.780943</td>\n",
       "      <td>0.050431</td>\n",
       "      <td>0.014236</td>\n",
       "      <td>0.026168</td>\n",
       "      <td>0.901576</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03-01-2019 12:34</td>\n",
       "      <td>b'@USCGHyderabad @TelanganaDGP @USAndHyderabad...</td>\n",
       "      <td>Appreciation</td>\n",
       "      <td>NS</td>\n",
       "      <td>1.050000e+18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Appreciation</td>\n",
       "      <td>True</td>\n",
       "      <td>0.002762</td>\n",
       "      <td>0.835799</td>\n",
       "      <td>0.001891</td>\n",
       "      <td>0.001063</td>\n",
       "      <td>0.012618</td>\n",
       "      <td>0.965338</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Date                                    Tweet Full Text  \\\n",
       "0      2/25/19 6:34  b'@zomatocare @hydcitypolice \\n@cyberabadpolic...   \n",
       "1      2/25/19 5:15  b'@hydcitypolice Sir, any updates regarding my...   \n",
       "2      2/24/19 5:59  b'@HYDTP @CPHydCity @hydcitypolice @TelanganaD...   \n",
       "3  03-01-2019 14:32  b'@HYDTP @hydcitypolice @AddlCPTrHyd Good init...   \n",
       "4  03-01-2019 12:34  b'@USCGHyderabad @TelanganaDGP @USAndHyderabad...   \n",
       "\n",
       "          Topic Action       user id  follower count  place   predictions  \\\n",
       "0        Others     NS  1.080000e+18             0.0    NaN        Others   \n",
       "1     Follow up      S  1.040000e+18             0.0    NaN     Follow up   \n",
       "2       Traffic     NS  1.090000e+18             0.0    NaN       Traffic   \n",
       "3  Appreciation     NS  1.400108e+08             0.0    NaN  Appreciation   \n",
       "4  Appreciation     NS  1.050000e+18             0.0    NaN  Appreciation   \n",
       "\n",
       "   classification_correct   sadness       joy      fear   disgust     anger  \\\n",
       "0                    True  0.105245  0.225655  0.001491  0.002787  0.023300   \n",
       "1                    True  0.162827  0.033009  0.013693  0.125967  0.187487   \n",
       "2                    True  0.141880  0.146321  0.088611  0.105356  0.080799   \n",
       "3                    True  0.054764  0.780943  0.050431  0.014236  0.026168   \n",
       "4                    True  0.002762  0.835799  0.001891  0.001063  0.012618   \n",
       "\n",
       "      score  location  \n",
       "0  0.339199      True  \n",
       "1 -0.761524      True  \n",
       "2  0.000000      True  \n",
       "3  0.901576      True  \n",
       "4  0.965338      True  "
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sadness,joy,fear,disgust,anger = [],[],[],[],[]\n",
    "for i in df['Tweet Full Text']:\n",
    "    response2 = natural_language_understanding.analyze(\n",
    "        text=i,\n",
    "        features=Features(emotion=EmotionOptions()),\n",
    "        language='en'\n",
    "    ).get_result()\n",
    "    mydict = json.loads(json.dumps(response2['emotion']['document']['emotion']))\n",
    "    sadness.append(mydict['sadness'])\n",
    "    joy.append(mydict['joy'])\n",
    "    fear.append(mydict['fear'])\n",
    "    disgust.append(mydict['disgust'])\n",
    "    anger.append(mydict['anger'])\n",
    "df['sadness'] = sadness\n",
    "df['joy'] = joy\n",
    "df['fear'] = fear\n",
    "df['disgust'] = disgust\n",
    "df['anger'] = anger\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Tweet Full Text</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Action</th>\n",
       "      <th>user id</th>\n",
       "      <th>follower count</th>\n",
       "      <th>place</th>\n",
       "      <th>predictions</th>\n",
       "      <th>classification_correct</th>\n",
       "      <th>sadness</th>\n",
       "      <th>joy</th>\n",
       "      <th>fear</th>\n",
       "      <th>disgust</th>\n",
       "      <th>anger</th>\n",
       "      <th>score</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2/25/19 6:34</td>\n",
       "      <td>b'@zomatocare @hydcitypolice \\n@cyberabadpolic...</td>\n",
       "      <td>Others</td>\n",
       "      <td>NS</td>\n",
       "      <td>1.080000e+18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Others</td>\n",
       "      <td>True</td>\n",
       "      <td>0.105245</td>\n",
       "      <td>0.225655</td>\n",
       "      <td>0.001491</td>\n",
       "      <td>0.002787</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>0.339199</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2/25/19 5:15</td>\n",
       "      <td>b'@hydcitypolice Sir, any updates regarding my...</td>\n",
       "      <td>Follow up</td>\n",
       "      <td>S</td>\n",
       "      <td>1.040000e+18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Follow up</td>\n",
       "      <td>True</td>\n",
       "      <td>0.162827</td>\n",
       "      <td>0.033009</td>\n",
       "      <td>0.013693</td>\n",
       "      <td>0.125967</td>\n",
       "      <td>0.187487</td>\n",
       "      <td>-0.761524</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2/24/19 5:59</td>\n",
       "      <td>b'@HYDTP @CPHydCity @hydcitypolice @TelanganaD...</td>\n",
       "      <td>Traffic</td>\n",
       "      <td>NS</td>\n",
       "      <td>1.090000e+18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Traffic</td>\n",
       "      <td>True</td>\n",
       "      <td>0.141880</td>\n",
       "      <td>0.146321</td>\n",
       "      <td>0.088611</td>\n",
       "      <td>0.105356</td>\n",
       "      <td>0.080799</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03-01-2019 14:32</td>\n",
       "      <td>b'@HYDTP @hydcitypolice @AddlCPTrHyd Good init...</td>\n",
       "      <td>Appreciation</td>\n",
       "      <td>NS</td>\n",
       "      <td>1.400108e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Appreciation</td>\n",
       "      <td>True</td>\n",
       "      <td>0.054764</td>\n",
       "      <td>0.780943</td>\n",
       "      <td>0.050431</td>\n",
       "      <td>0.014236</td>\n",
       "      <td>0.026168</td>\n",
       "      <td>0.901576</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03-01-2019 12:34</td>\n",
       "      <td>b'@USCGHyderabad @TelanganaDGP @USAndHyderabad...</td>\n",
       "      <td>Appreciation</td>\n",
       "      <td>NS</td>\n",
       "      <td>1.050000e+18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Appreciation</td>\n",
       "      <td>True</td>\n",
       "      <td>0.002762</td>\n",
       "      <td>0.835799</td>\n",
       "      <td>0.001891</td>\n",
       "      <td>0.001063</td>\n",
       "      <td>0.012618</td>\n",
       "      <td>0.965338</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Date                                    Tweet Full Text  \\\n",
       "0      2/25/19 6:34  b'@zomatocare @hydcitypolice \\n@cyberabadpolic...   \n",
       "1      2/25/19 5:15  b'@hydcitypolice Sir, any updates regarding my...   \n",
       "2      2/24/19 5:59  b'@HYDTP @CPHydCity @hydcitypolice @TelanganaD...   \n",
       "3  03-01-2019 14:32  b'@HYDTP @hydcitypolice @AddlCPTrHyd Good init...   \n",
       "4  03-01-2019 12:34  b'@USCGHyderabad @TelanganaDGP @USAndHyderabad...   \n",
       "\n",
       "          Topic Action       user id  follower count  place   predictions  \\\n",
       "0        Others     NS  1.080000e+18             0.0    NaN        Others   \n",
       "1     Follow up      S  1.040000e+18             0.0    NaN     Follow up   \n",
       "2       Traffic     NS  1.090000e+18             0.0    NaN       Traffic   \n",
       "3  Appreciation     NS  1.400108e+08             0.0    NaN  Appreciation   \n",
       "4  Appreciation     NS  1.050000e+18             0.0    NaN  Appreciation   \n",
       "\n",
       "   classification_correct   sadness       joy      fear   disgust     anger  \\\n",
       "0                    True  0.105245  0.225655  0.001491  0.002787  0.023300   \n",
       "1                    True  0.162827  0.033009  0.013693  0.125967  0.187487   \n",
       "2                    True  0.141880  0.146321  0.088611  0.105356  0.080799   \n",
       "3                    True  0.054764  0.780943  0.050431  0.014236  0.026168   \n",
       "4                    True  0.002762  0.835799  0.001891  0.001063  0.012618   \n",
       "\n",
       "      score location  \n",
       "0  0.339199    False  \n",
       "1 -0.761524    False  \n",
       "2  0.000000    False  \n",
       "3  0.901576    False  \n",
       "4  0.965338    False  "
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location = []\n",
    "for i in df['Tweet Full Text']:\n",
    "    response2 = natural_language_understanding.analyze(\n",
    "        text=i,\n",
    "        features=Features(entities=EntitiesOptions()),\n",
    "        language='en'\n",
    "    ).get_result()\n",
    "    try:\n",
    "        mydict['location'] = (json.loads(json.dumps(response2['entities'][0]['type'])) == 'Location')\n",
    "    except:\n",
    "        mydict['location'] = 'False'\n",
    "    location.append(mydict['location'])\n",
    "df['location'] = location\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Train data and Table data (tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('train_df.csv', sep=',', encoding='utf-8')\n",
    "# table.to_csv('table.csv', sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling for S and NS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 459 entries, 0 to 458\n",
      "Data columns (total 13 columns):\n",
      "Tweet Full Text           459 non-null object\n",
      "Topic                     459 non-null object\n",
      "Action                    459 non-null object\n",
      "predictions               459 non-null object\n",
      "classification_correct    459 non-null bool\n",
      "sadness                   459 non-null float64\n",
      "joy                       459 non-null float64\n",
      "fear                      459 non-null float64\n",
      "disgust                   459 non-null float64\n",
      "anger                     459 non-null float64\n",
      "score                     459 non-null float64\n",
      "location                  459 non-null bool\n",
      "pred                      459 non-null object\n",
      "dtypes: bool(2), float64(6), object(5)\n",
      "memory usage: 40.4+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('train_df.csv',delimiter=',')\n",
    "train_df['pred'] = train_df['predictions']\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 459 entries, 0 to 458\n",
      "Data columns (total 25 columns):\n",
      "Tweet Full Text                 459 non-null object\n",
      "Topic                           459 non-null object\n",
      "Action                          459 non-null object\n",
      "classification_correct          459 non-null bool\n",
      "sadness                         459 non-null float64\n",
      "joy                             459 non-null float64\n",
      "fear                            459 non-null float64\n",
      "disgust                         459 non-null float64\n",
      "anger                           459 non-null float64\n",
      "score                           459 non-null float64\n",
      "location                        459 non-null bool\n",
      "pred                            459 non-null object\n",
      "predictions_Appreciation        459 non-null uint8\n",
      "predictions_Community Action    459 non-null uint8\n",
      "predictions_Dissatisfaction     459 non-null uint8\n",
      "predictions_Fake News           459 non-null uint8\n",
      "predictions_Follow up           459 non-null uint8\n",
      "predictions_Fraud               459 non-null uint8\n",
      "predictions_General Info        459 non-null uint8\n",
      "predictions_Missing Person      459 non-null uint8\n",
      "predictions_Others              459 non-null uint8\n",
      "predictions_Query               459 non-null uint8\n",
      "predictions_Suggestion          459 non-null uint8\n",
      "predictions_Theft               459 non-null uint8\n",
      "predictions_Traffic             459 non-null uint8\n",
      "dtypes: bool(2), float64(6), object(4), uint8(13)\n",
      "memory usage: 42.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.get_dummies(train_df, columns=['predictions'], prefix = ['predictions'])\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_df['Action']\n",
    "train_x = train_df.drop(['pred','Action','Topic','Tweet Full Text','classification_correct'],axis=1)\n",
    "# train_x = train_df.drop(['pred','Action','Topic','Tweet Full Text','classification_correct','score','location','joy','sadness','fear','disgust','anger'],axis=1)\n",
    "# train_x = train_df[['score','predictions_Traffic']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 459 entries, 0 to 458\n",
      "Data columns (total 20 columns):\n",
      "sadness                         459 non-null float64\n",
      "joy                             459 non-null float64\n",
      "fear                            459 non-null float64\n",
      "disgust                         459 non-null float64\n",
      "anger                           459 non-null float64\n",
      "score                           459 non-null float64\n",
      "location                        459 non-null bool\n",
      "predictions_Appreciation        459 non-null uint8\n",
      "predictions_Community Action    459 non-null uint8\n",
      "predictions_Dissatisfaction     459 non-null uint8\n",
      "predictions_Fake News           459 non-null uint8\n",
      "predictions_Follow up           459 non-null uint8\n",
      "predictions_Fraud               459 non-null uint8\n",
      "predictions_General Info        459 non-null uint8\n",
      "predictions_Missing Person      459 non-null uint8\n",
      "predictions_Others              459 non-null uint8\n",
      "predictions_Query               459 non-null uint8\n",
      "predictions_Suggestion          459 non-null uint8\n",
      "predictions_Theft               459 non-null uint8\n",
      "predictions_Traffic             459 non-null uint8\n",
      "dtypes: bool(1), float64(6), uint8(13)\n",
      "memory usage: 27.9 KB\n"
     ]
    }
   ],
   "source": [
    "train_x.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9078947368421053"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_x, train_y, test_size=0.33, random_state=42)\n",
    "clf = svm.SVC(gamma='scale')\n",
    "clf.fit(X_train, y_train)\n",
    "# train_df['sns'] = clf.predict(train_x)\n",
    "# train_df['correct_sns'] = train_df['sns']==train_y\n",
    "# train_df['correct_sns'].mean()\n",
    "(clf.predict(X_test) == y_test).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8947368421052632"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_x, train_y, test_size=0.33, random_state=42)\n",
    "clf2 = LogisticRegression(solver='liblinear')\n",
    "clf2.fit(X_train, y_train)\n",
    "# train_df['sns'] = clf.predict(train_x)\n",
    "# train_df['correct_sns'] = train_df['sns']==train_y\n",
    "# train_df['correct_sns'].mean()\n",
    "(clf2.predict(X_test) == y_test).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7368421052631579"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_x, train_y, test_size=0.33, random_state=42)\n",
    "clf2 = tree.DecisionTreeClassifier()\n",
    "clf2.fit(X_train, y_train)\n",
    "# train_df['sns'] = clf.predict(train_x)\n",
    "# train_df['correct_sns'] = train_df['sns']==train_y\n",
    "# train_df['correct_sns'].mean()\n",
    "(clf2.predict(X_test) == y_test).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.743421052631579"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_x, train_y, test_size=0.33, random_state=42)\n",
    "clf = MLPClassifier(solver='liblinear', alpha=1e-5,hidden_layer_sizes=(10,8), random_state=1)\n",
    "clf2.fit(X_train, y_train)\n",
    "# train_df['sns'] = clf.predict(train_x)\n",
    "# train_df['correct_sns'] = train_df['sns']==train_y\n",
    "# train_df['correct_sns'].mean()\n",
    "(clf2.predict(X_test) == y_test).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
